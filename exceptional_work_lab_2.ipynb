{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images into image vector matrix - where each row is an image vector\n",
    "import os\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Path templates\n",
    "category_directories_template =  \"food_resized/*/[0-9]*_*\"\n",
    "image_files_template = \"food_resized/*/*/*.jpg\"\n",
    "\n",
    "#  return cid, name for a given category directory path i.e. \n",
    "# 'food_resized/train/0_hot_dog' ---> 0, \"hot_dog\"\n",
    "#       use: cid, name = cid_name_from_path(path_string)\n",
    "def cname_cid_from_path(path_string):\n",
    "    \n",
    "    base_dir = None\n",
    "    if os.path.isfile(path_string):\n",
    "        base_dir = os.path.basename(os.path.split(path_string)[0])\n",
    "    elif os.path.isdir(path_string):\n",
    "        base_dir = os.path.basename(path_string)\n",
    "    else: \n",
    "        raise(\"Error incorect path\")\n",
    "    \n",
    "    cid = int(base_dir.split('_')[0]) # get leading number, or cid\n",
    "    \n",
    "    idx = base_dir.find('_') + 1      # get trailing string after first '_'\n",
    "    cname = base_dir[idx:]\n",
    "\n",
    "    return cname, cid\n",
    "\n",
    "# {'chicken_wings': 0, 'dumplings': 1, 'hot_dog': 2, 'ramen': 3, 'sushi': 4}\n",
    "def get_category_cname_cid_map(category_directories_template):\n",
    "    category_folders = glob.glob(category_directories_template)\n",
    "    return dict(map(cname_cid_from_path, category_folders))\n",
    "\n",
    "def image_to_vector(image):\n",
    "    return image.reshape((1, -1)) / 255\n",
    "\n",
    "# image_vector of original size 60, 60, 3 back to np image\n",
    "def image_vector_to_image(image_vector, original_image_size=(60,60,3)):\n",
    "    image_vector = image_vector * 255\n",
    "    image_vector = image_vector.astype(int)\n",
    "    image_vector = image_vector.reshape(original_image_size)\n",
    "    return image_vector\n",
    "\n",
    "def get_sample_images_and_labels(images_file_template, gray=False):\n",
    "    \n",
    "    image_paths = glob.glob(image_files_template)\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for fname in image_paths:\n",
    "        \n",
    "        label, cid = cname_cid_from_path(fname)\n",
    "        \n",
    "        img = None\n",
    "        if gray == True:\n",
    "            img = cv2.imread(fname,0)\n",
    "        else:\n",
    "            img = cv2.imread(fname)\n",
    "        \n",
    "            # color stored in incorrect order for plt -> convert to RGB order\n",
    "            img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "        \n",
    "    return images, labels\n",
    "\n",
    "#load all images into matrix of image vectors, X, and corrresponding vector of categories, y\n",
    "def get_sample_image_vector_matrix_and_targets(images, labels, cname_cid_dict):\n",
    "    \n",
    "    X = image_to_vector(images[0])\n",
    "    y = []\n",
    "\n",
    "    for img, l in zip(images, labels):\n",
    "        \n",
    "        v = image_to_vector(img) # convert image to vector\n",
    "        X = np.vstack([X,v])     # add image vector to matrix\n",
    "        \n",
    "        y.append(cname_cid_dict[l])\n",
    "        \n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "#\n",
    "# load all images into matrix of image vectors, X, and corrresponding vector of categories, y\n",
    "#\n",
    "\n",
    "cname_cid_dict = get_category_cname_cid_map(category_directories_template) # get cname:cid dictonary\n",
    "images, labels = get_sample_images_and_labels(image_files_template, gray=False)\n",
    "\n",
    "% time X,y = get_sample_image_vector_matrix_and_targets(images, labels, cname_cid_dict)  \n",
    "\n",
    "# save original shape of images\n",
    "original_image_shape = images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# above operation takes a long time save results to files\n",
    "import pickle\n",
    "pickle.dump(X, open( 'large_data/X.p', 'wb' ))\n",
    "pickle.dump(y, open( 'large_data/y.p', 'wb' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "import pickle\n",
    "X = pickle.load(open( 'large_data/X.p', 'rb' ))\n",
    "y = pickle.load(open( 'large_data/y.p', 'rb' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "v = X[idx]\n",
    "\n",
    "image = image_vector_to_image(v, original_image_size=original_image_shape) #reconstruct image from vector\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(cv2.xfeatures2d.SIFT_create())\n",
    "help(cv2.xfeatures2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "def modified_sigmoid(x, k):\n",
    "     return 1 / (1 + math.exp(-x/k)) - 0.5\n",
    "\n",
    "def to_gray(image):\n",
    "    # converting image to grayscale\n",
    "    # must save the image again to use cv2.convert color, path must be relative\n",
    "    local_path = 'tmp.jpg'\n",
    "    cv2.imwrite(local_path, image)\n",
    "    img = cv2.imread(local_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    return gray\n",
    "\n",
    "\n",
    "def sift_distance(gray1, gray2, original=None):\n",
    "\n",
    "    img1 = gray1\n",
    "    img2 = gray2\n",
    "\n",
    "    # ORB Detector\n",
    "    #orb = cv2.ORB_create()\n",
    "    #kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "    #kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "\n",
    "    # Brute Force Matching\n",
    "    #bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    #matches = bf.match(des1, des2)\n",
    "    #matches = sorted(matches, key = lambda x:x.distance)\n",
    "    \n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    Sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp1, des1 = Sift.detectAndCompute(img1,None)\n",
    "    kp2, des2 = Sift.detectAndCompute(img2,None)\n",
    "    \n",
    "    # Brute Force Matching\n",
    "    bf = cv2.BFMatcher()\n",
    "    \n",
    "    matches = bf.knnMatch(des1,des2, k=2)\n",
    "\n",
    "    #Apply ratio test\n",
    "    threshold = 0.88\n",
    "    good_matches = 0\n",
    "    for m,n in matches:\n",
    "        if m.distance < threshold * n.distance:\n",
    "            good_matches += 1\n",
    "\n",
    "    return modified_sigmoid(good_matches, 5)\n",
    "\n",
    "\n",
    "# number of images\n",
    "n = X.shape[0]\n",
    "\n",
    "# distance matrix\n",
    "D = np.zeros(shape=(n,n))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for i in range(n):\n",
    "    print(\"%s \\% complete\" % (i/n))\n",
    "    for j in range(n):\n",
    "        \n",
    "        idx1= i\n",
    "        idx2 = j\n",
    "\n",
    "        im1 = image_vector_to_image(X[idx1])\n",
    "        im2 = image_vector_to_image(X[idx2])\n",
    "        gray1 = to_gray(im1)\n",
    "        gray2 = to_gray(im2)\n",
    "\n",
    "        sd = sift_distance(gray1, gray2)\n",
    "        \n",
    "        D[i,j] = sd\n",
    "        D[j,i] = sd\n",
    "\n",
    "        \n",
    "# set diagnols to zero\n",
    "np.fill_diagonal(D, 0)\n",
    "end = time.time()\n",
    "print(\"time: %s\" % (end - start))\n",
    "\n",
    "print(D)\n",
    "\n",
    "# above operation takes a long time save results to files\n",
    "import pickle\n",
    "pickle.dump(X, open( 'large_data/D.p', 'wb' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "import pickle\n",
    "D = pickle.load(open( 'large_data/D.p', 'rb' ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
